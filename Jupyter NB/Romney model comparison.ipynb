{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer as porterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney = pd.read_excel('training-Obama-Romney-tweets.xlsx', 'Romney', header=1)\n",
    "data_romney.rename(columns = {'Unnamed: 1':'date', 'Unnamed: 2':'time', \n",
    "                            '1: positive, -1: negative, 0: neutral, 2: mixed':'Anootated tweet'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney = data_romney.drop(['Unnamed: 0','date', 'time', 'Your class label', 'Unnamed: 6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney['Class'] = data_romney['Class'].apply(str)\n",
    "# print(data_obama[data_obama['Class']=='irrevelant'].count())\n",
    "# print(data_obama[data_obama['Class']=='irrelevant'].count())\n",
    "# print(data_obama[data_obama['Class']=='2'].count())\n",
    "# print(data_obama[data_obama['Class']=='1'].count())\n",
    "# print(data_obama[data_obama['Class']=='0'].count())\n",
    "# print(data_obama[data_obama['Class']=='-1'].count())\n",
    "\n",
    "data_romney = data_romney[(data_romney['Class'] == '1') | (data_romney['Class'] == '0') | (data_romney['Class'] == '-1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney['Class'] = data_romney['Class'].apply(int)\n",
    "data_romney = data_romney.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(tweet):\n",
    "    \n",
    "    filtered_tweet = [];\n",
    "\n",
    "    #stemming\n",
    "    porter = porterStemmer()\n",
    "    stemmedTweet = [porter.stem(word) for word in tweet.split(\" \")]\n",
    "    stemmedTweet = \" \".join(stemmedTweet)\n",
    "    tweet = str(stemmedTweet);\n",
    "    \n",
    "    tweet = tweet.replace(\"'\", \"\");\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = stop_words.union(['RT'])\n",
    "    \n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_tweet.append(w)\n",
    "    \n",
    "    eachTweet = \" \".join(filtered_tweet)  \n",
    "    \n",
    "    return eachTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(tweet):\n",
    "    \n",
    "    tweet_list = tweet.split()\n",
    "    lem = WordNetLemmatizer()\n",
    "    normalized_tweet = []\n",
    "    for word in tweet_list:\n",
    "        normalized_text = lem.lemmatize(word,'v')\n",
    "        normalized_tweet.append(normalized_text)\n",
    "        \n",
    "    eachTweet = \" \".join(normalized_tweet) \n",
    "\n",
    "    \n",
    "    return eachTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(row):\n",
    "    \n",
    "    text = row['Anootated tweet']\n",
    "    \n",
    "    # HTML Decoding\n",
    "    soup = BeautifulSoup(unescape(text), 'lxml')\n",
    "    text = soup.text\n",
    "    \n",
    "    # Remove emojis\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    text = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', text)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    text = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', text)\n",
    "    # Love -- <3, :*\n",
    "    text = re.sub(r'(<3|:\\*)', ' EMO_POS ', text)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    text = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', text)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    text = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', text)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    text = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', text)\n",
    "    \n",
    "    # Removing @\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "    \n",
    "    # Remove URL links\n",
    "    text = re.sub('https?://[A-Za-z0-9./]+','',text)\n",
    "    text = re.sub(r'www.[^ ]+', '', text)\n",
    "    \n",
    "    # Lower Case\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Remove words with repetition greater than 2\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    \n",
    "    # Remove negative patterns\n",
    "    text = neg_pattern.sub(lambda x: negations_dic[x.group()], text)\n",
    "    \n",
    "    # Remove Hashtags & Numbers\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # remove extra white spaces\n",
    "    text = re.sub(r'\\s+', r' ', text)\n",
    "    \n",
    "    #text = removeStopWords(text)\n",
    "    \n",
    "    #text = lemmatization(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney['Anootated tweet'] = data_romney.apply(preprocess_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training, validation and test dataset\n",
    "\n",
    "x = data_romney['Anootated tweet']\n",
    "y = data_romney['Class']\n",
    "SEED = 2000\n",
    "\n",
    "# Split data\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.1, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5083\n",
      "282\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_validation))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=100000, ngram_range=(1, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set TF-IDF params\n",
    "\n",
    "n_features=100000\n",
    "ngram_range=(1,3)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = stop_words.union(['rt'])\n",
    "\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "tvec.set_params(stop_words=None, max_features=n_features, ngram_range=ngram_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = ['-1', '0', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNBClassifier = MultinomialNB();\n",
    "\n",
    "checker_pipeline = Pipeline([\n",
    "            ('vectorizer', tvec),\n",
    "            ('classifier', multinomialNBClassifier)\n",
    "        ])\n",
    "\n",
    "sentiment_fit = checker_pipeline.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6028368794326241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      1.00      0.73       154\n",
      "           0       1.00      0.12      0.22        72\n",
      "           1       1.00      0.12      0.22        56\n",
      "\n",
      "    accuracy                           0.60       282\n",
      "   macro avg       0.86      0.42      0.39       282\n",
      "weighted avg       0.77      0.60      0.50       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment_fit.predict(x_validation)\n",
    "print(accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4734982332155477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.99      0.62       121\n",
      "           0       0.91      0.10      0.18       101\n",
      "           1       0.80      0.07      0.12        61\n",
      "\n",
      "    accuracy                           0.47       283\n",
      "   macro avg       0.72      0.39      0.31       283\n",
      "weighted avg       0.69      0.47      0.35       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC feature selection with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])\n",
    "\n",
    "checker_pipeline = Pipeline([\n",
    "            ('vectorizer', tvec),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "sentiment_fit = checker_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6170212765957447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.75      0.72       154\n",
      "           0       0.47      0.43      0.45        72\n",
      "           1       0.55      0.48      0.51        56\n",
      "\n",
      "    accuracy                           0.62       282\n",
      "   macro avg       0.57      0.56      0.56       282\n",
      "weighted avg       0.61      0.62      0.61       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment_fit.predict(x_validation)\n",
    "print(accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6325088339222615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.81      0.72       121\n",
      "           0       0.62      0.45      0.52       101\n",
      "           1       0.61      0.59      0.60        61\n",
      "\n",
      "    accuracy                           0.63       283\n",
      "   macro avg       0.63      0.62      0.61       283\n",
      "weighted avg       0.63      0.63      0.62       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney_test = pd.read_excel('test.xlsx', 'Romney')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney_test['Class'] = data_romney_test['Class'].apply(str)\n",
    "# print(data_obama[data_obama['Class']=='irrevelant'].count())\n",
    "# print(data_obama[data_obama['Class']=='irrelevant'].count())\n",
    "# print(data_obama[data_obama['Class']=='2'].count())\n",
    "# print(data_obama[data_obama['Class']=='1'].count())\n",
    "# print(data_obama[data_obama['Class']=='0'].count())\n",
    "# print(data_obama[data_obama['Class']=='-1'].count())\n",
    "\n",
    "data_romney_test = data_romney_test[(data_romney_test['Class'] == '1') | (data_romney_test['Class'] == '0') | (data_romney_test['Class'] == '-1')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anootated tweet    1900\n",
       "Class              1900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_romney_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney_test['Class'] = data_romney_test['Class'].apply(int)\n",
    "data_romney_test = data_romney_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anootated tweet    1900\n",
       "Class              1900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_romney_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_romney_test['Anootated tweet'] = data_romney_test.apply(preprocess_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6157894736842106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.79      0.72       960\n",
      "           0       0.52      0.39      0.45       555\n",
      "           1       0.61      0.50      0.55       385\n",
      "\n",
      "    accuracy                           0.62      1900\n",
      "   macro avg       0.59      0.56      0.57      1900\n",
      "weighted avg       0.60      0.62      0.60      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(data_romney_test['Anootated tweet'])\n",
    "print(accuracy_score(data_romney_test['Class'], y_pred_test))\n",
    "print(classification_report(data_romney_test['Class'], y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = LinearSVC()\n",
    "\n",
    "checker_pipeline = Pipeline([\n",
    "            ('vectorizer', tvec),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "sentiment_fit = checker_pipeline.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6276595744680851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.79      0.74       154\n",
      "           0       0.47      0.39      0.43        72\n",
      "           1       0.59      0.48      0.53        56\n",
      "\n",
      "    accuracy                           0.63       282\n",
      "   macro avg       0.58      0.55      0.56       282\n",
      "weighted avg       0.61      0.63      0.62       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment_fit.predict(x_validation)\n",
    "print(accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6219081272084805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.83      0.71       121\n",
      "           0       0.65      0.45      0.53       101\n",
      "           1       0.60      0.51      0.55        61\n",
      "\n",
      "    accuracy                           0.62       283\n",
      "   macro avg       0.62      0.59      0.59       283\n",
      "weighted avg       0.63      0.62      0.61       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = RidgeClassifier()\n",
    "\n",
    "checker_pipeline = Pipeline([\n",
    "            ('vectorizer', tvec),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "sentiment_fit = checker_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624113475177305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.82      0.74       154\n",
      "           0       0.46      0.35      0.40        72\n",
      "           1       0.65      0.43      0.52        56\n",
      "\n",
      "    accuracy                           0.62       282\n",
      "   macro avg       0.59      0.53      0.55       282\n",
      "weighted avg       0.61      0.62      0.61       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment_fit.predict(x_validation)\n",
    "print(accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6148409893992933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.84      0.70       121\n",
      "           0       0.64      0.41      0.50       101\n",
      "           1       0.65      0.51      0.57        61\n",
      "\n",
      "    accuracy                           0.61       283\n",
      "   macro avg       0.63      0.59      0.59       283\n",
      "weighted avg       0.62      0.61      0.60       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LINEAR SVC FEATURE SELECTION WITH MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
