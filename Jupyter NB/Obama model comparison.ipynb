{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer as porterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama = pd.read_excel('training-Obama-Romney-tweets.xlsx', 'Obama', header=1)\n",
    "data_obama.rename(columns = {'Unnamed: 1':'date', 'Unnamed: 2':'time', \n",
    "                            '1: positive, -1: negative, 0: neutral, 2: mixed':'Anootated tweet'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama = data_obama.drop(['Unnamed: 0','date', 'time', 'Your class', 'Unnamed: 6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama['Class'] = data_obama['Class'].apply(str)\n",
    "# print(data_obama[data_obama['Class']=='irrevelant'].count())\n",
    "# print(data_obama[data_obama['Class']=='irrelevant'].count())\n",
    "# print(data_obama[data_obama['Class']=='2'].count())\n",
    "# print(data_obama[data_obama['Class']=='1'].count())\n",
    "# print(data_obama[data_obama['Class']=='0'].count())\n",
    "# print(data_obama[data_obama['Class']=='-1'].count())\n",
    "\n",
    "data_obama = data_obama[(data_obama['Class'] == '1') | (data_obama['Class'] == '0') | (data_obama['Class'] == '-1')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama['Class'] = data_obama['Class'].apply(int)\n",
    "data_obama = data_obama.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(tweet):\n",
    "    \n",
    "    filtered_tweet = [];\n",
    "\n",
    "    #stemming\n",
    "    porter = porterStemmer()\n",
    "    stemmedTweet = [porter.stem(word) for word in tweet.split(\" \")]\n",
    "    stemmedTweet = \" \".join(stemmedTweet)\n",
    "    tweet = str(stemmedTweet);\n",
    "    \n",
    "    tweet = tweet.replace(\"'\", \"\");\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = stop_words.union(['RT'])\n",
    "    \n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_tweet.append(w)\n",
    "    \n",
    "    eachTweet = \" \".join(filtered_tweet)  \n",
    "    \n",
    "    return eachTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(tweet):\n",
    "    \n",
    "    tweet_list = tweet.split()\n",
    "    lem = WordNetLemmatizer()\n",
    "    normalized_tweet = []\n",
    "    for word in tweet_list:\n",
    "        normalized_text = lem.lemmatize(word,'v')\n",
    "        normalized_tweet.append(normalized_text)\n",
    "        \n",
    "    eachTweet = \" \".join(normalized_tweet) \n",
    "    \n",
    "    return eachTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(row):\n",
    "    \n",
    "    text = row['Anootated tweet']\n",
    "    \n",
    "    # HTML Decoding\n",
    "    soup = BeautifulSoup(unescape(text), 'lxml')\n",
    "    text = soup.text\n",
    "    \n",
    "    # Remove emojis\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    text = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', text)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    text = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', text)\n",
    "    # Love -- <3, :*\n",
    "    text = re.sub(r'(<3|:\\*)', ' EMO_POS ', text)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    text = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', text)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    text = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', text)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    text = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', text)\n",
    "    \n",
    "    # Removing @\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "    \n",
    "    # Remove URL links\n",
    "    text = re.sub('https?://[A-Za-z0-9./]+','',text)\n",
    "    text = re.sub(r'www.[^ ]+', '', text)\n",
    "    \n",
    "    # Lower Case\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Remove words with repetition greater than 2\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    \n",
    "    # Remove negative patterns\n",
    "    text = neg_pattern.sub(lambda x: negations_dic[x.group()], text)\n",
    "    \n",
    "    # Remove Hashtags & Numbers\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # remove extra white spaces\n",
    "    text = re.sub(r'\\s+', r' ', text)\n",
    "    \n",
    "    text = removeStopWords(text)\n",
    "    \n",
    "    text = lemmatization(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama['Anootated tweet'] = data_obama.apply(preprocess_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training, validation and test dataset\n",
    "\n",
    "x = data_obama['Anootated tweet']\n",
    "y = data_obama['Class']\n",
    "SEED = 2000\n",
    "\n",
    "# Split data\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.1, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5061\n",
      "281\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_validation))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=100000, ngram_range=(1, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set TF-IDF params\n",
    "\n",
    "n_features=100000\n",
    "ngram_range=(1,3)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = stop_words.union(['rt'])\n",
    "\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "tvec.set_params(stop_words=None, max_features=n_features, ngram_range=ngram_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = ['-1', '0', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNBClassifier = MultinomialNB();\n",
    "checker_pipeline = Pipeline([\n",
    "            ('vectorizer', tvec),\n",
    "            ('classifier', multinomialNBClassifier)\n",
    "        ])\n",
    "sentiment_fit = checker_pipeline.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sentiment_fit.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6263345195729537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.73      0.65        92\n",
      "           0       0.62      0.52      0.57       102\n",
      "           1       0.69      0.64      0.67        87\n",
      "\n",
      "    accuracy                           0.63       281\n",
      "   macro avg       0.63      0.63      0.63       281\n",
      "weighted avg       0.63      0.63      0.62       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6418439716312057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.76      0.69       102\n",
      "           0       0.64      0.52      0.57        97\n",
      "           1       0.65      0.64      0.65        83\n",
      "\n",
      "    accuracy                           0.64       282\n",
      "   macro avg       0.64      0.64      0.64       282\n",
      "weighted avg       0.64      0.64      0.64       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = LinearSVC()\n",
    "\n",
    "checker_pipeline = Pipeline([\n",
    "            ('vectorizer', tvec),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "sentiment_fit = checker_pipeline.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6227758007117438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.68      0.67        92\n",
      "           0       0.62      0.47      0.53       102\n",
      "           1       0.60      0.74      0.66        87\n",
      "\n",
      "    accuracy                           0.62       281\n",
      "   macro avg       0.62      0.63      0.62       281\n",
      "weighted avg       0.62      0.62      0.62       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment_fit.predict(x_validation)\n",
    "print(accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6418439716312057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.74      0.71       102\n",
      "           0       0.66      0.47      0.55        97\n",
      "           1       0.59      0.72      0.65        83\n",
      "\n",
      "    accuracy                           0.64       282\n",
      "   macro avg       0.64      0.64      0.64       282\n",
      "weighted avg       0.65      0.64      0.64       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf = RidgeClassifier()\n",
    "\n",
    "checker_pipeline = Pipeline([\n",
    "            ('vectorizer', tvec),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "sentiment_fit = checker_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6298932384341637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.71      0.67        92\n",
      "           0       0.65      0.47      0.55       102\n",
      "           1       0.62      0.74      0.67        87\n",
      "\n",
      "    accuracy                           0.63       281\n",
      "   macro avg       0.63      0.64      0.63       281\n",
      "weighted avg       0.63      0.63      0.62       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment_fit.predict(x_validation)\n",
    "print(accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648936170212766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.75      0.71       102\n",
      "           0       0.68      0.48      0.57        97\n",
      "           1       0.59      0.72      0.65        83\n",
      "\n",
      "    accuracy                           0.65       282\n",
      "   macro avg       0.65      0.65      0.64       282\n",
      "weighted avg       0.65      0.65      0.64       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RIDGE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama_test = pd.read_excel('test.xlsx', 'Obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to punch &lt;e&gt;Obama&lt;/e&gt; in the face. So...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;e&gt;Obama&lt;/e&gt; wants to tax foreign earnings. Th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;e&gt;Obama&lt;/e&gt; has to maintain his professionali...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hate &lt;e&gt;Obama&lt;/e&gt; with a BURNING PASSION #de...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't like&lt;e&gt;Obama&lt;/e&gt; because his stupid &lt;a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Anootated tweet Class\n",
       "0  I'd like to punch <e>Obama</e> in the face. So...    -1\n",
       "1  <e>Obama</e> wants to tax foreign earnings. Th...    -1\n",
       "2  <e>Obama</e> has to maintain his professionali...     1\n",
       "3  I hate <e>Obama</e> with a BURNING PASSION #de...    -1\n",
       "4  I don't like<e>Obama</e> because his stupid <a...    -1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obama_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama_test['Class'] = data_obama_test['Class'].apply(str)\n",
    "# print(data_obama[data_obama['Class']=='irrevelant'].count())\n",
    "# print(data_obama[data_obama['Class']=='irrelevant'].count())\n",
    "# print(data_obama[data_obama['Class']=='2'].count())\n",
    "# print(data_obama[data_obama['Class']=='1'].count())\n",
    "# print(data_obama[data_obama['Class']=='0'].count())\n",
    "# print(data_obama[data_obama['Class']=='-1'].count())\n",
    "\n",
    "data_obama_test = data_obama_test[(data_obama_test['Class'] == '1') | (data_obama_test['Class'] == '0') | (data_obama_test['Class'] == '-1')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to punch &lt;e&gt;Obama&lt;/e&gt; in the face. So...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;e&gt;Obama&lt;/e&gt; wants to tax foreign earnings. Th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;e&gt;Obama&lt;/e&gt; has to maintain his professionali...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hate &lt;e&gt;Obama&lt;/e&gt; with a BURNING PASSION #de...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't like&lt;e&gt;Obama&lt;/e&gt; because his stupid &lt;a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Anootated tweet Class\n",
       "0  I'd like to punch <e>Obama</e> in the face. So...    -1\n",
       "1  <e>Obama</e> wants to tax foreign earnings. Th...    -1\n",
       "2  <e>Obama</e> has to maintain his professionali...     1\n",
       "3  I hate <e>Obama</e> with a BURNING PASSION #de...    -1\n",
       "4  I don't like<e>Obama</e> because his stupid <a...    -1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obama_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anootated tweet    1951\n",
       "Class              1951\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obama_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama_test['Class'] = data_obama_test['Class'].apply(int)\n",
    "data_obama_test = data_obama_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anootated tweet    1951\n",
       "Class              1951\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obama_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obama_test['Anootated tweet'] = data_obama_test.apply(preprocess_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566888774987186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.65      0.61       688\n",
      "           0       0.56      0.48      0.52       681\n",
      "           1       0.57      0.57      0.57       582\n",
      "\n",
      "    accuracy                           0.57      1951\n",
      "   macro avg       0.57      0.57      0.56      1951\n",
      "weighted avg       0.57      0.57      0.56      1951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = sentiment_fit.predict(data_obama_test['Anootated tweet'])\n",
    "print(accuracy_score(data_obama_test['Class'], y_pred_test))\n",
    "print(classification_report(data_obama_test['Class'], y_pred_test, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
